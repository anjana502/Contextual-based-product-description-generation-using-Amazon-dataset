{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Create character-to-index (char2idx) and index-to-character (idx2char) mappings\n",
    "vocab = sorted(set(text))\n",
    "seq_length = 40\n",
    "char2idx = {char: idx for idx, char in enumerate(vocab)}\n",
    "char2idx['<UNK>'] = len(char2idx)  # Handle unknown characters\n",
    "idx2char = np.array(vocab + ['<UNK>'])\n",
    "\n",
    "text = \"This phone has an amazing display and great battery life! Overall, it's a great phone for everyday use, with top-notch performance. I would highly recommend it to anyone looking for a new phone.\"\n",
    "text = re.sub(r'[^a-zA-Z0-9 ]+', '', text.lower())\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "sequences = tokenizer.texts_to_sequences([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(vocab), output_dim=64, input_length=seq_length),\n",
    "    LSTM(128, return_sequences=True, recurrent_dropout=0.2),\n",
    "    LSTM(128, return_sequences=False, recurrent_dropout=0.2),\n",
    "    Dropout(0.2),\n",
    "    Dense(len(vocab), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_with_temperature(predictions, temperature=1.0):\n",
    "    predictions = np.asarray(predictions).astype('float64')\n",
    "    predictions = np.log(predictions + 1e-8) / temperature\n",
    "    exp_preds = np.exp(predictions)\n",
    "    predictions = exp_preds / np.sum(exp_preds)\n",
    "    return np.random.choice(len(predictions), p=predictions)\n",
    "\n",
    "def generate_text(model, start_string, gen_length=100, temperature=1.0):\n",
    "    input_eval = [char2idx.get(char, char2idx['<UNK>']) for char in start_string]\n",
    "    input_eval = np.array(input_eval).reshape(1, -1)\n",
    "    generated_text = start_string\n",
    "    for _ in range(gen_length):\n",
    "        predictions = model.predict(input_eval, verbose=0)\n",
    "        predicted_idx = sample_with_temperature(predictions[0], temperature)\n",
    "        next_char = idx2char[predicted_idx] if predicted_idx < len(idx2char) else '<UNK>'\n",
    "        generated_text += next_char\n",
    "        input_eval = np.append(input_eval[:, 1:], [[predicted_idx]], axis=1)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phone isT!.st TtTzOeu-sgiwpd'k .Ibf!TnmvIllnszch.ka-oTzIT'I!gno'i!!t ,hdvl' I-gt'-mu'elduzweapm!OfIlhTTmvh'ot'e.-da.c kbudfyfilckOevbanssunvOmb'pb-uTbitywsma,dgm-naivnncaayIlTmhgbsktu-zk!vdklhTfkdTpgp-pk,zkom\n"
     ]
    }
   ],
   "source": [
    "start_string = u\"phone is\"\n",
    "print(generate_text(model, start_string, gen_length=200))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
